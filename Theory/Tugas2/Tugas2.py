# -*- coding: utf-8 -*-
"""Tugas2DM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LdhOC-gtzjc68DqelsMqQ7OnMHd-ewf8

**Data** **Exploration**
"""

#import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#importing the dataset
df = pd.read_csv("kecelakaan.csv")
df.info()

"""**Feature Importance**"""

colormap = plt.cm.viridis
plt.figure(figsize=(12,12))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sns.heatmap(updated_df.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)
plt.savefig('FI.png')

"""**Data Prepocessing**

Feature Selection
"""

df.drop("Name",axis=1,inplace=True)
df.drop("Ticket",axis=1,inplace=True)
df.drop("PassengerId",axis=1,inplace=True)
df.info()

"""Fill the Missing Value

"""

print(df.isnull().sum())

updated_df = df
updated_df['Age']=updated_df['Age'].fillna(updated_df['Age'].mean()) #Use the attribute mean to fill in the missing value
# updated_df['Cabin']=updated_df['Cabin'].fillna('U') #Use a global constant to fill in the missing value
# updated_df['Embarked']=updated_df['Embarked'].fillna('S') #fill these with the most common one.
updated_df['Embarked']=updated_df['Embarked'].fillna(updated_df['Embarked'].mode()[0]) #Use the attribute mode to fill in the missing value
updated_df.drop("Cabin",axis=1,inplace=True)
updated_df.isnull().sum()

"""Encoded to Numerical Value"""

updated_df.head()

updated_df['Sex'] = updated_df['Sex'].map({'male':0, 'female':1})
updated_df['Embarked'] = updated_df['Embarked'].map({'C':0, 'Q':1, 'S':2})

updated_df.head()

"""**Data** **Classifcation**"""

#split dataset in features and target variable
feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
X = updated_df[feature_cols] # Features
y = updated_df.Survived # Target variable

# Import train_test_split function
from sklearn.model_selection import train_test_split

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

# Print the Confusion Matrix and slice it into four pieces
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion matrix:\n', cm)

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='sigmoid') # sigmoid Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

# Print the Confusion Matrix and slice it into four pieces
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion matrix:\n', cm)

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='rbf') # rbf Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

# Print the Confusion Matrix and slice it into four pieces
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion matrix:\n', cm)

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='poly', degree=8) # Poly Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(y_test, y_pred))

# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(y_test, y_pred))

# Print the Confusion Matrix and slice it into four pieces
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print('Confusion matrix:\n', cm)

"""**Data Visualization**"""

# No. of survivors and non-survivors of the incident
# total_survived = updated_df["Survived"].sum() # sum of rows
# total_deceased = len(updated_df["Survived"]) - total_survived
# print("Out of {} passengers, {} died {} survived ".format(len(updated_df), total_deceased, total_survived))

sns.factorplot('Survived',data=updated_df,kind='count')
print(pd.crosstab(updated_df["Survived"],updated_df.Survived))
plt.savefig('Survived.png')

# Group the dataset by Pclass and Survived and then unstack them
group = updated_df.groupby(['Pclass', 'Survived'])
pclass_survived = group.size().unstack()
 
# Heatmap - Color encoded 2D representation of data.
sns.heatmap(pclass_survived, annot = True, fmt ="d")
plt.savefig('Pclass.png')

print(pd.crosstab(updated_df["Sex"],updated_df.Survived))
# Countplot
sns.catplot(x ="Sex", hue ="Survived", kind ="count", data = updated_df)
plt.savefig('Sex.png')

# Violinplot Displays distribution of data
# across all levels of a category.
sns.violinplot(x ="Sex", y ="Age", hue ="Survived",data = updated_df, split = True)
plt.savefig('Age.png')

# Adding a column Family_Size
updated_df['Family_Size'] = 0
updated_df['Family_Size'] = updated_df['Parch']+updated_df['SibSp']
 
# Adding a column Alone
updated_df['Alone'] = 0
updated_df.loc[updated_df.Family_Size == 0, 'Alone'] = 1
 
# Factorplot for Family_Size
sns.factorplot(x ='Family_Size', y ='Survived', data = updated_df)
plt.savefig('FamilySize.png')
 
# Factorplot for Alone
sns.factorplot(x ='Alone', y ='Survived', data = updated_df)
plt.savefig('Alone.png')

# Divide Fare into 4 bins
updated_df['Fare_Range'] = pd.qcut(updated_df['Fare'], 4)
 
# Barplot - Shows approximate values based
# on the height of bars.
sns.barplot(x ='Fare_Range', y ='Survived',data = updated_df)
plt.savefig('Fare.png')

# Countplot
sns.catplot(x ='Embarked', hue ='Survived',kind ='count', col ='Pclass', data = updated_df)
plt.savefig('Embarked.png')